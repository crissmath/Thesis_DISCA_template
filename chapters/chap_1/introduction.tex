\chapter{Foundation of Innovation: Introduction to Machine Learning and FPGA}

Over recent decades, the realm of machine learning has experienced a series of transformative advancements. This progress has been fueled by the convergence of increased computational power, the availability of vast and varied datasets to the public, and the emergence of user-friendly deep learning platforms such as Tensorflow, Torch, and Caffe. Notably, technologies like \acp{CNN} and \acp{DNN} have ushered in a new era for computer vision and data analytics, finding applications and addressing challenges across a diverse range of fields.


\section{Catalysts of Change: Motivation}


\section{Blueprint for Innovation: Objectives}

The main objective of this PhD thesis is to propose ...

To achieve this overall goal, several sub-objectives must be defined. These are the following:

\begin{itemize}
    \item Create a simulation environment that allows the development of new solutions for
    \item Devise an algorithm to optimize the assignment of 
    \item Propose an efficient 
    \item Propose a novel solution to enable changing the 
    \item Develop a control mechanism that allows adjusting
\end{itemize}


\section{Navigational Map: Structure of the Thesis}
The thesis dissertation is organized into eight chapters. Next, we briefly describe the contents of each part:

In \textbf{\autoref{chapter:ml_fpga_basics}. \nameref{chapter:ml_fpga_basics}:} we start by explaining the fundamentals of machine learning and FPGA technologies. We discuss their synergies and the potential for acceleration.

In \textbf{\autoref{chapter:fpga_performance_modeling}. \nameref{chapter:fpga_performance_modeling}:} we introduce our performance modeling approaches for FPGA-based machine learning solutions, their potential impacts, and limitations. 

In \textbf{\autoref{chapter:algorithm_implementation_fpga}. \nameref{chapter:algorithm_implementation_fpga}:} we present our first implementations of machine learning algorithms on FPGA. We elaborate on the design choices and optimizations.

We continue with \textbf{\autoref{chapter:enhancing_ml_performance_fpga}. \nameref{chapter:enhancing_ml_performance_fpga}:} detailing our approaches to enhance the performance and efficiency of ML algorithms on FPGA platforms.

In \textbf{\autoref{chapter:parallel_computing_ml_fpga}. \nameref{chapter:parallel_computing_ml_fpga}:}, we delve into advanced techniques for implementing parallel computing structures for ML on FPGAs, discussing the benefits and challenges.

Finally, in \textbf{\autoref{chapter:conclusion_future_work}. \nameref{chapter:conclusion_future_work}:}, we conclude this dissertation by summarizing the main findings, discussing the implications of our research, and suggesting avenues for future work.

